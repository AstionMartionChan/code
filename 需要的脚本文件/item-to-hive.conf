## dependency relevant

#spark.jars=hdfs://localhost/user/zhoujy/jars/guava-16.0.jar
#spark.driver.extraClassPath=guava-16.0.jar
#spark.executor.extraClassPath=guava-16.0.jar

# zip jars/*
#spark.yarn.jars=

## computation relevant

spark.output.partition=10
spark.streaming.duration=300000
spark.task.maxFailures=4
spark.streaming.kafka.maxRatePerPartition=5000
spark.sql.shuffle.partitions=50

# dynamic resources allocation

## other

#spark.kafka.offset.storage=mysql
#spark.kafka.offset.mysql.url=jdbc:mysql://172.27.2.251:4310/wutiao?useSSL=false
#spark.kafka.offset.mysql.user=data_test
#spark.kafka.offset.mysql.password=data_test_pass
#spark.kafka.offset.mysql.table=kafka_to_hive_topic_partition
#spark.kafka.offset.mysql.restart-from=2018-07-10\ 17:30:00
#spark.kafka.offset.mysql.restart-from=

spark.kafka.offset.zookeeper.connect=172.27.6.54:2181,172.27.6.103:2181,172.27.6.141:2181
spark.streaming.ui.retainedBatches=500
spark.streaming.stopGracefullyOnShutdown=true
spark.ui.showConsoleProgress=false
spark.yarn.submit.waitAppCompletion=false
spark.hive.url=hwwg-bigdata-hadoopnn-prod-1
spark.hive.port=9083
#spark.metrics.conf=/Users/zhoujy/spark-2.2.0-bin-hadoop2.7/metrics.properties
