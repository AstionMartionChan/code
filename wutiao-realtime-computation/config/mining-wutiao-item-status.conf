## dependency relevant

# zip jars/*
#spark.yarn.jars=

## computation relevant

spark.output.partition=10
spark.streaming.duration=60000
spark.task.maxFailures=4
spark.streaming.kafka.maxRatePerPartition=10000
spark.sql.shuffle.partitions=50

# dynamic resources allocation

## other

spark.kafka.offset.storage=mysql
spark.kafka.offset.mysql.url=jdbc:mysql://172.27.2.251:4310/wutiao?useSSL=false
spark.kafka.offset.mysql.user=data_test
spark.kafka.offset.mysql.password=data_test_pass
spark.kafka.offset.mysql.table=kafka_to_hive_topic_partition
spark.kafka.offset.mysql.restart-from=2018-07-03\ 15:43:00

#spark.kafka.offset.zookeeper.connect=172.27.6.54:2181,172.27.6.103:2181,172.27.6.141:2181,172.27.6.183:2181,172.27.6.122:2181
spark.streaming.ui.retainedBatches=500
spark.streaming.stopGracefullyOnShutdown=true
spark.ui.showConsoleProgress=false
spark.yarn.submit.waitAppCompletion=false
#spark.hive.url=hwwg-bigdata-hadoopnn-prod-1
#spark.hive.port=9083
#spark.metrics.conf=/Users/zhoujy/spark-2.2.0-bin-hadoop2.7/metrics.properties